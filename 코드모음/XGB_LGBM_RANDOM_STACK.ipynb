import pandas as pd
import numpy as np
from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    f1_score,
    precision_score,
    recall_score,
)
from sklearn.model_selection import train_test_split
from impyute.imputation.cs import mice
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.impute import SimpleImputer

import pandas as pd
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
import seaborn as sns
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE

from sklearn.ensemble import StackingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

df_train = pd.read_csv("train.csv") # 학습용 데이터
df_test = pd.read_csv("submission.csv") # 테스트 데이터(제출파일의 데이터)


def remove_feature(df, col):
    df.drop(columns=col,inplace=True)
    return df

#1. customer_country1. 삭제
remove_feature(df_train,["customer_country.1"])
remove_feature(df_test,["customer_country.1"])

#2. product_subcategory 삭제
remove_feature(df_train,["product_subcategory"])
remove_feature(df_test,["product_subcategory"])


#3. product_modelname 삭제
remove_feature(df_train,["product_modelname"])
remove_feature(df_test,["product_modelname"])

#4. business_subarea 삭제
remove_feature(df_train,["business_subarea"])
remove_feature(df_test,["business_subarea"])


def replace_outliers(df, col_name):
    Q1 = df[col_name].quantile(0.25)
    Q3 = df[col_name].quantile(0.75)
    IQR = Q3 - Q1

    # 상하한값 설정
    lower_limit = Q1 - 1.5 * IQR
    upper_limit = Q3 + 1.5 * IQR

    # 이상치를 상하한값으로 대체
    df[col_name] = df[col_name].apply(lambda x: min(max(x, lower_limit), upper_limit))
    
    return df


#1. lead_desc_length에 대해서 이상치 상하한값 대체
replace_outliers(df_train,'lead_desc_length')
replace_outliers(df_test,'lead_desc_length')

#2. ver_win_rate_x에 대해서 이상치 상하한값 대체
replace_outliers(df_train,'ver_win_rate_x')
replace_outliers(df_test,'ver_win_rate_x')

#3. ver_win_ratio_per_bu에 대해서 이상치 상하한값 대체
replace_outliers(df_train,'ver_win_ratio_per_bu')
replace_outliers(df_test,'ver_win_ratio_per_bu')

# 기간 범주화 및 결측치 처리
def simplify_expected_timeline(row):
    if pd.isna(row):
        return 'Unknown'
    elif 'less than 3 months' in row:
        return 'less than 3 months'
    elif '3 months ~ 6 months' in row:
        return '3 months ~ 6 months'
    elif '6 months ~ 9 months' in row:
        return '6 months ~ 9 months'
    elif '9 months ~ 1 year' in row:
        return '9 months ~ 1 year'
    elif 'more than a year' in row:
        return 'more than a year'
    else:
        return 'Unknown'


# 'inquiry_type' 열의 최빈값을 계산
mode_value = df_train['inquiry_type'].mode()[0]
mode_value2 = df_test['inquiry_type'].mode()[0]

mode_value3 = df_train['product_category'].mode()[0]
mode_value4 = df_test['product_category'].mode()[0]


def impute_missing_values(df):
    # 1-1. com_reg_ver_win_rate의 결측치를 lead_owner의 분포를 이용해 중앙값으로 대체
    com_reg_missing = df.groupby('lead_owner')['com_reg_ver_win_rate'].median()
    for lead_owner, median_value in com_reg_missing.items():
        df.loc[(df['lead_owner'] == lead_owner) & (df['com_reg_ver_win_rate'].isnull()), 'com_reg_ver_win_rate'] = median_value

    # 1-2. com_reg_ver_win_rate에 대해 처리되지 않은 결측치들은 전체 중앙값으로 대체
    overall_median_com_reg_missing = df['com_reg_ver_win_rate'].median()
    df['com_reg_ver_win_rate'].fillna(overall_median_com_reg_missing, inplace=True)
    
    # 2. historical_existing_cnt에 대한 결측치 0으로
    df['historical_existing_cnt'].fillna(0, inplace=True)

    # 3. 가중치를 나타내는 세 피처에 대해 결측값을 0으로
    df['id_strategic_ver'].fillna(0, inplace=True)
    df['it_strategic_ver'].fillna(0, inplace=True)
    df['idit_strategic_ver'].fillna(0, inplace=True)

    # 4. ver_pro와 ver_win_rate_x의 상관관계를 통해 결측치 중앙값으로 대체
    median_ver_win_rate_x_for_ver_pro_0 = df.loc[df['ver_pro'] == 0, 'ver_win_rate_x'].median()
    median_ver_win_rate_x_for_ver_pro_1 = df.loc[df['ver_pro'] == 1, 'ver_win_rate_x'].median()
    df.loc[(df['ver_win_rate_x'].isnull()) & (df['ver_pro'] == 0), 'ver_win_rate_x'] = median_ver_win_rate_x_for_ver_pro_0
    df.loc[(df['ver_win_rate_x'].isnull()) & (df['ver_pro'] == 1), 'ver_win_rate_x'] = median_ver_win_rate_x_for_ver_pro_1

    # 5-1. ver_win_ratio_per_bu에 대해 결측값은 business unit별 중앙값으로
    bu_median_ver_win_ratio_per_bu = df.groupby('business_unit')['ver_win_ratio_per_bu'].median()
    for business_unit, median_value in bu_median_ver_win_ratio_per_bu.items():
        df.loc[(df['business_unit'] == business_unit) & (df['ver_win_ratio_per_bu'].isnull()), 'ver_win_ratio_per_bu'] = median_value

    # 5-2. ver_win_ratio_per_bu에 대해 처리되지 않은 결측값들은 전체 중앙값으로 대체
    overall_median_ver_win_ratio_per_bu = df['ver_win_ratio_per_bu'].median()
    df['ver_win_ratio_per_bu'].fillna(overall_median_ver_win_ratio_per_bu, inplace=True)
    
    #6 customer_country OT로 결측값 대체
    df['customer_country'].fillna('OT', inplace=True)
    
    #7-1 customer-type에서 유사 카테고리 통합
    df['customer_type'] = df['customer_type'].replace({
        'End Customer': 'End-Customer',
        'Specifier/ Influencer': 'Specifier/Influencer',
        'Specifier / Influencer': 'Specifier/Influencer',
        'Home Owner': 'Homeowner',
        'End-user': 'End-User',
        'Software/Solution Provider': 'Software/Solution Provider',
        'Software / Solution Provider': 'Software/Solution Provider',
        'Others': 'Other',
        'Dealer/Distributor': 'Distributor',
    
        })
        #7-2 customer_type Other로 결측값 대체
    df['customer_type'].fillna('Other', inplace=True)
    
    #8-1 customer_job other로 결측값 대체
    df['customer_job'].fillna('other', inplace=True)
    
    #8-2 customer_job에서 매우 낮은 빈도로 출현하는 직업을 other로 대체
    customer_job_distribution = df['customer_job'].value_counts(dropna=False)
    top_n_categories = customer_job_distribution.index[:10]  # 상위 10개 카테고리
    df['customer_job'] = df['customer_job'].apply(lambda x: x if x in top_n_categories else 'other')
    
    # 9-1 inquiry_type에대해서 대소문자 통일, 유사 카테고리 통합
    df['inquiry_type'] = df['inquiry_type'].str.lower()
    df['inquiry_type'] = df['inquiry_type'].replace({
        'quotation or purchase consultation': 'quotation or purchase consultation',  
        })
    #9-2 inquiry_type에 대해서 결측값 other로 대체
    #df['inquiry_type'].fillna('other', inplace=True)
    # 'inquiry_type' 열의 누락된 값을 최빈값으로 대체
    df['inquiry_type'].fillna(mode_value, inplace=True)
    
    #10 product_cateogry에 대해서 결측값 other로 대체
    #df['product_category'].fillna('other', inplace=True)
    df['product_category'].fillna(mode_value, inplace=True)
    
    #11 expected_timeline 기간 통일하고, 결측값 unknown으로 대체
    df['expected_timeline'] = df['expected_timeline'].apply(simplify_expected_timeline)

    #12 business_area 결측값 other로 대체
    df['business_area'].fillna('other', inplace=True)
    
    return df

df_train = impute_missing_values(df_train)
df_test = impute_missing_values(df_test)


def label_encoding(series: pd.Series) -> pd.Series:
    """범주형 데이터를 시리즈 형태로 받아 숫자형 데이터로 변환합니다."""

    my_dict = {}

    # 모든 요소를 문자열로 변환
    series = series.astype(str)

    for idx, value in enumerate(sorted(series.unique())):
        my_dict[value] = idx
    series = series.map(my_dict)

    return series

# 레이블 인코딩할 칼럼들
label_columns = [
    "customer_country",
    "business_area",
    "business_unit",
    "customer_type",
    "enterprise",
    "customer_job",
    "inquiry_type",
    "product_category",
    "customer_position",
    "response_corporate",
    "expected_timeline",
    
]
df_all = pd.concat([df_train[label_columns], df_test[label_columns]])

for col in label_columns:
    df_all[col] = label_encoding(df_all[col])


for col in label_columns:  
    df_train[col] = df_all.iloc[: len(df_train)][col]
    df_test[col] = df_all.iloc[len(df_train) :][col]

# 데이터 준비
X_train, X_val, y_train, y_val = train_test_split(df_train.drop("is_converted", axis=1),
                                                    df_train["is_converted"],
                                                    test_size=0.2,
                                                    shuffle=True,
                                                    random_state=400)


smote = SMOTE(random_state=1234)


scale_pos_weight_value = (len(y_train) - sum(y_train)) / sum(y_train)

# 기본 분류기들 정의
estimators = [
    ('lgbm', LGBMClassifier(n_estimators=500, learning_rate=0.05, max_depth=7, num_leaves=2 ** 5, force_row_wise=True,
                             random_state=1234, min_child_samples=10, scale_pos_weight=scale_pos_weight_value)),
    ('xgb', XGBClassifier(n_estimators= 800, learning_rate=0.05, max_depth=6, random_state=1234, scale_pos_weight=scale_pos_weight_value)),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=1234))
]

# 메타 분류기 정의
meta_classifier = LogisticRegression()

# StackingClassifier 정의
stacking_clf = StackingClassifier(estimators=estimators, final_estimator=meta_classifier)

X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# StackingClassifier 학습
stacking_clf.fit(X_resampled, y_resampled)

# 학습 데이터에 대한 예측
pred_train = stacking_clf.predict(X_resampled)

# 검증 데이터에 대한 예측
pred_val = stacking_clf.predict(X_val)

def get_clf_eval(y_test, y_pred=None):
    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, labels=[True, False])
    recall = recall_score(y_test, y_pred)
    F1 = f1_score(y_test, y_pred, labels=[True, False])

    print("오차행렬:\n", confusion)
    print("\n정확도: {:.4f}".format(accuracy))
    print("정밀도: {:.4f}".format(precision))
    print("재현율: {:.4f}".format(recall))
    print("F1: {:.4f}".format(F1))

pred = stacking_clf.predict(X_train)
pred2 = stacking_clf.predict(X_val)

# 결과 출력
print("training에 대한 f1 \n")
print(get_clf_eval(y_resampled, pred_train))

print("======================")

print("validation에 대한 f1 \n")
print(get_clf_eval(y_val, pred_val))

# 테스트 데이터에 대한 예측
x_test = df_test.drop(["is_converted", "id"], axis=1)
test_pred = stacking_clf.predict(x_test)

print("True로 예측된 개수:", sum(test_pred))

# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)
df_sub = pd.read_csv("submission.csv")
df_sub["is_converted"] = test_pred

# 제출 파일 저장
df_sub.to_csv("submission_X_L_R_STACK.csv", index=False)
